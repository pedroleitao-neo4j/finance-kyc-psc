{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "866f7e2c",
   "metadata": {},
   "source": [
    "# Spotting Potential Fraud Patterns with Neo4j\n",
    "\n",
    "Financial crime is rarely an isolated event committed by a single rogue actor - it is almost always a connected phenomenon involving intricate networks of people, companies, and locations. Traditional fraud detection systems, which typically analyze data in tabular silos, often struggle to identify these complex schemes because they lack the ability to traverse relationships. By shifting the perspective to a graph-based approach, organizations can uncover the structural patterns that underpin systematic fraud, money laundering, and evasion. This notebook moves beyond simple entity resolution to explore three specific, high-risk topologies that are frequently indicative of illicit activity.\n",
    "\n",
    "The first pattern we analyze is the phenomenon of **\"Registration Factories.\"** In shell company laundering, quantity has a quality all its own. Fraudsters often require a large volume of disposable corporate entities to layer illicit funds or facilitate \"long firm\" fraud. To achieve this, they frequently register hundreds or even thousands of companies at a single physical address, often a residential property or a modest virtual office. While formation agents legitimately host multiple businesses, extreme outliers - where a single postcode hosts a density of companies akin to a skyscraper - are a primary red flag for \"company mills\" designed to mass-produce corporate vehicles for criminal misuse.\n",
    "\n",
    "We then turn our attention to **\"Circular Ownership\"** loops. This is a sophisticated obfuscation technique where ownership chains are engineered to loop back on themselvesâ€”for example, Company A owns Company B, which owns Company C, which in turn owns Company A. These \"Russian Doll\" structures serve a dual purpose: they artificially inflate the capital on a company's balance sheet without any actual injection of funds, and more critically, they decapitate the ownership structure. By creating a closed loop, fraudsters can effectively hide the Ultimate Beneficial Owner (UBO), making it nearly impossible for standard due diligence processes to identify who is actually in control, thereby evading sanctions lists and KYC checks.\n",
    "\n",
    "Finally, we investigate the **\"Offshore Nexus,\"** visualizing the flow of control from domestic assets to high-secrecy jurisdictions such as Jersey, Guernsey, and the Isle of Man. While offshore ownership can be legitimate, it is also a classic vector for tax evasion, capital flight, and the concealment of assets. By mapping the \"flight paths\" of corporate control, we can identify specific districts in the UK that are disproportionately owned by offshore interests. This geospatial perspective helps compliance teams prioritize their investigations, focusing on clusters where the ownership trail goes cold in jurisdictions known for their opacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c92d5323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USER = os.getenv(\"NEO4J_USER\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "NEO4J_DATABASE = os.getenv(\"NEO4J_DATABASE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50485e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_analysis import Neo4jAnalysis\n",
    "\n",
    "# Initialize the analysis helper\n",
    "analysis = Neo4jAnalysis(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD, NEO4J_DATABASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e580288b",
   "metadata": {},
   "source": [
    "## Registration Factories: Identifying High-Density Company Registrations\n",
    "\n",
    "To identify potential fraud patterns, we can analyze the density of company registrations in specific locations. A high concentration of company registrations in a particular area may indicate the presence of a \"registration factory,\" where multiple companies are registered at the same address, sometimes for fraudulent purposes.\n",
    "\n",
    "We can analyze the company registration data to find locations with a high number of registered companies. This can be done using a Cypher query to count the number of companies registered at each address and then visualizing the results on a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83a02dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "factory_district_query = \"\"\"\n",
    "MATCH (c:Company)-[:REGISTERED_AT]->(a:Address)\n",
    "WHERE a.latitude IS NOT NULL AND a.longitude IS NOT NULL\n",
    "\n",
    "// Filter for Active companies only\n",
    "MATCH (c)-[:HAS_STATUS]->(s:CompanyStatus)\n",
    "WHERE s.name = 'Active'\n",
    "\n",
    "// Extract the District (e.g., 'EC2M' from 'EC2M 7PP')\n",
    "WITH split(a.postcode, ' ')[0] AS district, a.line_1 AS address_line_1, a.postcode AS postcode, count(c) AS company_count\n",
    "\n",
    "// Filter for significant volume to focus the map on high-density areas\n",
    "WHERE company_count > 1000\n",
    "\n",
    "RETURN district, address_line_1, postcode, company_count\n",
    "ORDER BY company_count DESC\n",
    "LIMIT 100\n",
    "\"\"\"\n",
    "\n",
    "df = analysis.run_query_df(factory_district_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74ad5eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address_line_1</th>\n",
       "      <th>postcode</th>\n",
       "      <th>company_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71-75 SHELTON STREET</td>\n",
       "      <td>WC2H 9JQ</td>\n",
       "      <td>68776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3RD FLOOR, 86-90</td>\n",
       "      <td>EC2A 4NE</td>\n",
       "      <td>13639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>167-169 GREAT PORTLAND STREET</td>\n",
       "      <td>W1W 5PF</td>\n",
       "      <td>8627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85 GREAT PORTLAND STREET</td>\n",
       "      <td>W1W 7LT</td>\n",
       "      <td>6637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50 LOTHIAN ROAD</td>\n",
       "      <td>EH3 9WJ</td>\n",
       "      <td>5778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2ND FLOOR COLLEGE HOUSE</td>\n",
       "      <td>HA4 7AE</td>\n",
       "      <td>4433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>320 FIRECREST COURT</td>\n",
       "      <td>WA1 1RG</td>\n",
       "      <td>4122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3RD FLOOR</td>\n",
       "      <td>EC2A 4NE</td>\n",
       "      <td>4087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>101 NEW CAVENDISH STREET</td>\n",
       "      <td>W1W 6XH</td>\n",
       "      <td>2642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>82A JAMES CARTER ROAD</td>\n",
       "      <td>IP28 7DE</td>\n",
       "      <td>2350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  address_line_1  postcode  company_count\n",
       "0           71-75 SHELTON STREET  WC2H 9JQ          68776\n",
       "1               3RD FLOOR, 86-90  EC2A 4NE          13639\n",
       "2  167-169 GREAT PORTLAND STREET   W1W 5PF           8627\n",
       "3       85 GREAT PORTLAND STREET   W1W 7LT           6637\n",
       "4                50 LOTHIAN ROAD   EH3 9WJ           5778\n",
       "5        2ND FLOOR COLLEGE HOUSE   HA4 7AE           4433\n",
       "6            320 FIRECREST COURT   WA1 1RG           4122\n",
       "7                      3RD FLOOR  EC2A 4NE           4087\n",
       "8       101 NEW CAVENDISH STREET   W1W 6XH           2642\n",
       "9          82A JAMES CARTER ROAD  IP28 7DE           2350"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the top 10 locations for factory registrations, ordered by company count\n",
    "df.sort_values(by=\"company_count\", ascending=False).head(10)[\n",
    "    [\"address_line_1\", \"postcode\", \"company_count\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0cdc34",
   "metadata": {},
   "source": [
    "And we can now geographically visualize all the top districts, where a specific address with more than 1000 companies registered, is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfa646a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import re\n",
    "import pydeck as pdk\n",
    "import matplotlib\n",
    "import matplotlib.colors as mcolors\n",
    "import json\n",
    "\n",
    "\n",
    "# Fetch GeoJSON Boundaries\n",
    "def get_postcode_area(district):\n",
    "    # Extracts the leading letters (e.g., \"SW\" from \"SW1A\", \"B\" from \"B1\")\n",
    "    match = re.match(r\"([A-Z]+)\", district, re.I)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "\n",
    "df[\"area\"] = df[\"district\"].apply(get_postcode_area)\n",
    "unique_areas = df[\"area\"].dropna().unique()\n",
    "\n",
    "# Repository for UK Postcode Polygons\n",
    "base_url = \"https://raw.githubusercontent.com/missinglink/uk-postcode-polygons/refs/heads/master/geojson\"\n",
    "gdf_list = []\n",
    "\n",
    "for area in unique_areas:\n",
    "    url = f\"{base_url}/{area.upper()}.geojson\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            area_gdf = gpd.read_file(io.BytesIO(response.content))\n",
    "            gdf_list.append(area_gdf)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {area}: {e}\")\n",
    "\n",
    "if not gdf_list:\n",
    "    raise ValueError(\"No GeoJSON data could be retrieved.\")\n",
    "\n",
    "# Combine into one GeoDataFrame\n",
    "full_gdf = pd.concat(gdf_list, ignore_index=True)\n",
    "if full_gdf.crs and full_gdf.crs.to_string() != \"EPSG:4326\":\n",
    "    full_gdf = full_gdf.to_crs(epsg=4326)\n",
    "\n",
    "# Merge with our company counts\n",
    "# The GeoJSON 'name' property matches the district (e.g., \"AB10\")\n",
    "merged_gdf = full_gdf.merge(df, left_on=\"name\", right_on=\"district\", how=\"left\")\n",
    "merged_gdf[\"company_count\"] = merged_gdf[\"company_count\"].fillna(0)\n",
    "\n",
    "# We use a Red scale to indicate 'Risk/Intensity'\n",
    "cmap = matplotlib.colormaps[\"Reds\"]\n",
    "norm = mcolors.LogNorm(vmin=100, vmax=merged_gdf[\"company_count\"].max())\n",
    "\n",
    "\n",
    "def get_fill_color(count):\n",
    "    if count < 100:\n",
    "        return [50, 50, 50, 50]  # Grey/Transparent for low density\n",
    "    rgba = cmap(norm(count))\n",
    "    return [int(rgba[0] * 255), int(rgba[1] * 255), int(rgba[2] * 255), 200]\n",
    "\n",
    "\n",
    "merged_gdf[\"fill_color\"] = merged_gdf[\"company_count\"].apply(get_fill_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63ffbbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_data_dict = json.loads(merged_gdf.to_json())\n",
    "\n",
    "view_state = pdk.ViewState(\n",
    "    latitude=54.5,\n",
    "    longitude=-3.0,\n",
    "    zoom=6.5,\n",
    "    pitch=45,\n",
    "    bearing=0,\n",
    ")\n",
    "\n",
    "layer = pdk.Layer(\n",
    "    \"GeoJsonLayer\",\n",
    "    data=geo_data_dict,\n",
    "    opacity=0.8,\n",
    "    stroked=True,\n",
    "    filled=True,\n",
    "    extruded=True,  # Extrude based on count\n",
    "    wireframe=False,\n",
    "    get_fill_color=\"properties.fill_color\",\n",
    "    get_line_color=[255, 255, 255, 80],\n",
    "    # Scale elevation: Taller bars = More Companies = Higher Risk\n",
    "    get_elevation=\"properties.company_count * 2\",\n",
    "    get_line_width=20,\n",
    "    pickable=True,\n",
    "    auto_highlight=True,\n",
    ")\n",
    "\n",
    "r = pdk.Deck(\n",
    "    layers=[layer],\n",
    "    initial_view_state=view_state,\n",
    "    map_style=pdk.map_styles.CARTO_DARK,\n",
    "    tooltip={\n",
    "        \"html\": \"<b>District:</b> {name}<br/><b>Active Companies:</b> {company_count}\"\n",
    "    },\n",
    ")\n",
    "\n",
    "# Save and Render\n",
    "html_path = \"renderings/registration_factory_density_choropleth.html\"\n",
    "r.to_html(html_path, notebook_display=False)\n",
    "\n",
    "# Optional: Snapshot (requires the helper from your notebook)\n",
    "await analysis.capture_graph_to_png(\n",
    "    html_content=None,\n",
    "    output_path=\"renderings/registration_factory_density_choropleth.png\",\n",
    "    scale=1,\n",
    "    width=1500,\n",
    "    height=1920,\n",
    "    html_file=html_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d8d6f3",
   "metadata": {},
   "source": [
    "![Registration Factory Density Choropleth](renderings/registration_factory_density_choropleth.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357c7dc9",
   "metadata": {},
   "source": [
    "## Circular ownership loops\n",
    "\n",
    "Circular ownership loops occur when a company is indirectly owned by itself through a chain of ownership. These loops can be indicative of complex corporate structures used to obscure the true ownership of a company, which may be a red flag for fraudulent activities or money laundering.\n",
    "\n",
    "Because of the complexity of these loops, they can be difficult to detect using traditional methods. However, graph databases like Neo4j are perfectly suited for identifying such patterns due to their ability to efficiently traverse relationships.\n",
    "\n",
    "> Circular ownership loops start with a company, go through a series of ownership relationships, and eventually loop back to the original company. For example, Company A owns Company B, Company B owns Company C, and Company C owns Company A. This doesn't necessarily indicate fraud on its own, but it can be a sign of an attempt to hide the true ownership of a company or to create a complex structure that is difficult to analyze, and it may warrant further investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4080f1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "circular_ownership_query = \"\"\"\n",
    "// MATCH: Find a path that starts and ends at the same Company\n",
    "// We increase the max depth to 12 to allow for larger loops (e.g., 6 controllers)\n",
    "MATCH path = (c:Company)-[:CONTROLS|SAME_AS*1..12]->(c)\n",
    "\n",
    "// FILTER: \"Five or more controlling entities\"\n",
    "// We count how many 'CONTROLS' relationships exist in the path.\n",
    "// Each 'CONTROLS' relationship represents one entity exerting power.\n",
    "WHERE size([r IN relationships(path) WHERE type(r) = 'CONTROLS']) >= 5\n",
    "\n",
    "RETURN path\n",
    "\"\"\"\n",
    "\n",
    "response = analysis.run_query_viz(circular_ownership_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a072d94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_viz.neo4j import from_neo4j, ColorSpace\n",
    "\n",
    "# Run the query (using the query string above)\n",
    "results = analysis.run_query_viz(circular_ownership_query)\n",
    "\n",
    "colors = {\n",
    "    \"Country\": \"#1f77b4\",  # Blue for Countries\n",
    "    \"Address\": \"#ff7f0e\",  # Orange for Addresses\n",
    "    \"Person\": \"#2ca02c\",  # Green for Persons\n",
    "    \"PreviousName\": \"#d62728\",  # Red for Previous Names\n",
    "    \"SICCode\": \"#9467bd\",  # Purple for SIC Codes\n",
    "    \"Company\": \"#8c564b\",  # Brown for Companies\n",
    "    \"CompanyCategory\": \"#e377c2\",  # Pink for Company Categories\n",
    "    \"CompanyStatus\": \"#7f7f7f\",  # Gray for Company Statuses\n",
    "    \"SupervisoryAuthority\": \"#bcbd22\",  # Olive for Supervisory Authorities\n",
    "    \"AuthorisedCorporateServiceProvider\": \"#17becf\",  # Cyan for Authorised Corporate Service Providers,\n",
    "    \"Organization\": \"#aec7e8\",  # Light Blue for Organizations,\n",
    "}\n",
    "\n",
    "VG = from_neo4j(results)\n",
    "\n",
    "VG.color_nodes(\n",
    "    field=\"caption\",  # Using the internal labels property\n",
    "    color_space=ColorSpace.DISCRETE,\n",
    "    colors=colors,\n",
    ")\n",
    "VG.resize_relationships(\n",
    "    property=\"thickness\",\n",
    ")\n",
    "VG.color_relationships(\n",
    "    property=\"thickness\",\n",
    "    color_space=ColorSpace.DISCRETE,\n",
    "    colors={\n",
    "        1: \"blue\",  # Blue for low control (<=25% voting and share rights)\n",
    "        2: \"orange\",  # Orange for medium control (26-50% voting and share rights)\n",
    "        3: \"red\",  # Red for high control (51-75% voting and share rights)\n",
    "        4: \"purple\",  # Purple for anything else (>75% voting and share rights)\n",
    "    },\n",
    ")\n",
    "\n",
    "label_to_property = {\"Organization\": \"uid\", \"Person\": \"id\", \"Company\": \"uid\"}\n",
    "\n",
    "analysis.set_caption_by_label(VG, label_to_property)\n",
    "\n",
    "generated_html = VG.render(layout=\"forcedirected\", initial_zoom=0.7)\n",
    "\n",
    "await analysis.capture_graph_to_png(\n",
    "    generated_html, \"renderings/circular_ownership_loops.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f39e426",
   "metadata": {},
   "source": [
    "![Circular Ownership Loops](renderings/circular_ownership_loops.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524cbdca",
   "metadata": {},
   "source": [
    "## Offshore Company Concentration: Identifying High-Density Offshore Registrations\n",
    "\n",
    "Offshore company registrations can be a red flag for potential fraud, as they are often used to hide assets, avoid taxes, or engage in illicit activities. By analyzing the concentration of offshore company registrations in specific jurisdictions, we can identify areas that may warrant further investigation.\n",
    "\n",
    "Let us produce a geographical visualization of the top districts in the offshore jurisdictions with the highest concentration of company registrations. This can help us identify potential hotspots for fraudulent activities.\n",
    "\n",
    "> The plot below shows concentration by the width of the arcs towards the offshore jurisdictions, can you spot the thick arc landing near Portsmouth ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11ad5b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_offshore_query = \"\"\"\n",
    "MATCH (controller)-[:BASED_IN|RESIDES_IN]->(country:Country)\n",
    "WHERE country.name IN ['Jersey', 'Guernsey', 'Isle of Man']\n",
    "\n",
    "MATCH (controller)-[:CONTROLS]->(c:Company)-[:HAS_STATUS]->(s:CompanyStatus)\n",
    "WHERE s.name = 'Active'\n",
    "\n",
    "MATCH (c)-[:REGISTERED_AT]->(ca:Address)\n",
    "WHERE ca.postcode IS NOT NULL\n",
    "\n",
    "// Extract the Outcode/District\n",
    "WITH country.name AS Jurisdiction, split(ca.postcode, ' ')[0] AS District, count(c) AS Company_Count\n",
    "WHERE Company_Count >= 10\n",
    "RETURN Jurisdiction, District, Company_Count\n",
    "ORDER BY Company_Count DESC\n",
    "LIMIT 10000\n",
    "\"\"\"\n",
    "\n",
    "df = analysis.run_query_df(aggregated_offshore_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6fc2782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pgeocode\n",
    "\n",
    "# Geocode UK Districts (Source)\n",
    "nomi = pgeocode.Nominatim(\"gb\")\n",
    "\n",
    "# Get unique districts from the query result to minimize API calls/lookups\n",
    "unique_districts = df[\"District\"].unique()\n",
    "geo_results = nomi.query_postal_code(unique_districts)\n",
    "\n",
    "# Create a lookup dictionary: District -> [Lat, Lon]\n",
    "district_map = geo_results.set_index(\"postal_code\")[\n",
    "    [\"latitude\", \"longitude\"]\n",
    "].T.to_dict(\"list\")\n",
    "\n",
    "# Map the coordinates back to the main DataFrame\n",
    "df[\"src_lat\"] = df[\"District\"].map(lambda x: district_map.get(x, [None, None])[0])\n",
    "df[\"src_lon\"] = df[\"District\"].map(lambda x: district_map.get(x, [None, None])[1])\n",
    "\n",
    "OFFSHORE_CENTROIDS = {\n",
    "    \"Jersey\": [-2.1312, 49.2144],\n",
    "    \"Guernsey\": [-2.5853, 49.4482],\n",
    "    \"Isle of Man\": [-4.5481, 54.2361],\n",
    "}\n",
    "\n",
    "df[\"tgt_lon\"] = df[\"Jurisdiction\"].apply(\n",
    "    lambda x: OFFSHORE_CENTROIDS.get(x, [None, None])[0]\n",
    ")\n",
    "df[\"tgt_lat\"] = df[\"Jurisdiction\"].apply(\n",
    "    lambda x: OFFSHORE_CENTROIDS.get(x, [None, None])[1]\n",
    ")\n",
    "\n",
    "# Drop invalid rows (where geocoding failed)\n",
    "df_clean = df.dropna(subset=[\"src_lat\", \"src_lon\", \"tgt_lat\", \"tgt_lon\"]).copy()\n",
    "\n",
    "geo_data_dict = json.loads(df_clean.to_json(orient=\"records\"))\n",
    "\n",
    "view_state = pdk.ViewState(\n",
    "    latitude=49.1,  # Just south of Jersey (approx. St Helier is 49.18)\n",
    "    longitude=-2.1,  # Roughly aligned with the gap between Jersey and France\n",
    "    zoom=8,  # Closer zoom to emphasize the islands\n",
    "    pitch=55,  # Slightly lower pitch to see the \"landing\" of arcs in London\n",
    "    bearing=15,  # Bearing NNE towards London (approx 0.1W)\n",
    ")\n",
    "\n",
    "layer = pdk.Layer(\n",
    "    \"ArcLayer\",\n",
    "    data=geo_data_dict,\n",
    "    get_source_position=[\"src_lon\", \"src_lat\"],\n",
    "    get_target_position=[\"tgt_lon\", \"tgt_lat\"],\n",
    "    get_source_color=[0, 255, 128, 140],\n",
    "    get_target_color=[255, 0, 0, 140],\n",
    "    # DYNAMIC WIDTH: Scale thickness based on Company_Count\n",
    "    # We use a log-like scaling or simple multiplier so huge districts don't cover the map\n",
    "    get_width=\"1 + (Company_Count / 100)\",\n",
    "    get_tilt=15,\n",
    "    pickable=True,\n",
    "    auto_highlight=True,\n",
    ")\n",
    "\n",
    "r = pdk.Deck(\n",
    "    layers=[layer],\n",
    "    initial_view_state=view_state,\n",
    "    map_style=pdk.map_styles.CARTO_DARK,\n",
    "    tooltip={\n",
    "        \"html\": \"<b>District:</b> {District}<br/>\"\n",
    "        \"<b>Offshore Haven:</b> {Jurisdiction}<br/>\"\n",
    "        \"<b>Controlled Companies:</b> {Company_Count}\"\n",
    "    },\n",
    ")\n",
    "\n",
    "html_path = \"renderings/aggregated_offshore_arcs.html\"\n",
    "r.to_html(html_path, notebook_display=False)\n",
    "\n",
    "await analysis.capture_graph_to_png(\n",
    "    html_content=None,\n",
    "    output_path=\"renderings/aggregated_offshore_arcs.png\",\n",
    "    scale=1,\n",
    "    width=1500,\n",
    "    height=1920,\n",
    "    html_file=html_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a0d194",
   "metadata": {},
   "source": [
    "![High-Density Offshore Registrations](renderings/aggregated_offshore_arcs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecee7f8",
   "metadata": {},
   "source": [
    "## What is in a name ?\n",
    "\n",
    "There are many use cases where certain names can be a red flag for potential fraud. For example, if a company has a name that is very similar to a well-known brand, it could be an attempt to deceive customers or investors. Frequent name changing can also be a red flag, as it may indicate an attempt to avoid detection or to create confusion. Additionally, names that include certain keywords (e.g., \"offshore,\" \"investment,\" \"holding\") may warrant further scrutiny, especially if they are associated with high-risk jurisdictions or industries.\n",
    "\n",
    "### Reputation laundering\n",
    "\n",
    "In the following query, we screen the entire history of a company, not just its current legal name. It traverses the `HAS_PREVIOUS_NAME` and `PREVIOUS_NAME_OF` chain to find if any past identity matches a high-risk keyword (e.g., \"Crypto\", \"Capital\", or a specific sanctioned entity name). This is crucial because a company might change its name to \"Generic Holdings Ltd\" specifically to hide its past association with a collapsed crypto exchange or a sanctioned entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "137342eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_ID</th>\n",
       "      <th>Incorporation_Date</th>\n",
       "      <th>Name_Changed_Date</th>\n",
       "      <th>Matched_Keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>09221291</td>\n",
       "      <td>2014-09-16</td>\n",
       "      <td>2025-02-28</td>\n",
       "      <td>CRYPTO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16157727</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>2026-01-30</td>\n",
       "      <td>FX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13684038</td>\n",
       "      <td>2021-10-17</td>\n",
       "      <td>2023-05-01</td>\n",
       "      <td>CRYPTO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13079328</td>\n",
       "      <td>2020-12-14</td>\n",
       "      <td>2025-03-05</td>\n",
       "      <td>CRYPTO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13766183</td>\n",
       "      <td>2021-11-25</td>\n",
       "      <td>2025-03-05</td>\n",
       "      <td>CRYPTO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12218786</td>\n",
       "      <td>2019-09-20</td>\n",
       "      <td>2021-07-28</td>\n",
       "      <td>FX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>06483658</td>\n",
       "      <td>2008-01-25</td>\n",
       "      <td>2010-04-15</td>\n",
       "      <td>FX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15207218</td>\n",
       "      <td>2023-10-12</td>\n",
       "      <td>2023-11-07</td>\n",
       "      <td>FX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16098093</td>\n",
       "      <td>2024-11-25</td>\n",
       "      <td>2025-02-17</td>\n",
       "      <td>FX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11383083</td>\n",
       "      <td>2018-05-25</td>\n",
       "      <td>2019-01-30</td>\n",
       "      <td>CRYPTO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company_ID Incorporation_Date Name_Changed_Date Matched_Keyword\n",
       "0   09221291         2014-09-16        2025-02-28          CRYPTO\n",
       "1   16157727         2024-12-31        2026-01-30              FX\n",
       "2   13684038         2021-10-17        2023-05-01          CRYPTO\n",
       "3   13079328         2020-12-14        2025-03-05          CRYPTO\n",
       "4   13766183         2021-11-25        2025-03-05          CRYPTO\n",
       "5   12218786         2019-09-20        2021-07-28              FX\n",
       "6   06483658         2008-01-25        2010-04-15              FX\n",
       "7   15207218         2023-10-12        2023-11-07              FX\n",
       "8   16098093         2024-11-25        2025-02-17              FX\n",
       "9   11383083         2018-05-25        2019-01-30          CRYPTO"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reputation_laundering_query = \"\"\"\n",
    "/// MATCH: Traverse the full history of company names\n",
    "MATCH path = (c:Company)-[:HAS_PREVIOUS_NAME|PREVIOUS_NAME_OF*]->(prev:PreviousName)\n",
    "\n",
    "// FILTER: Check if ANY previous name contains high-risk keywords\n",
    "WHERE prev.name CONTAINS 'CRYPTO'\n",
    "   OR prev.name CONTAINS 'FX'\n",
    "\n",
    "// REFINE: Ensure the *current* name does NOT contain these keywords\n",
    "AND NOT c.name CONTAINS 'CRYPTO'\n",
    "AND NOT c.name CONTAINS 'FX'\n",
    "\n",
    "RETURN\n",
    "    c.number AS Company_ID,\n",
    "    c.incorporation_date AS Incorporation_Date,\n",
    "    // Extract the date the name was changed (stored on the relationship)\n",
    "    last(relationships(path)).changed_on AS Name_Changed_Date,\n",
    "    // We check the previous name against the list and return the first match found.\n",
    "    head([word IN ['CRYPTO', 'FX'] WHERE prev.name CONTAINS word]) AS Matched_Keyword\n",
    "LIMIT 20;\n",
    "\"\"\"\n",
    "\n",
    "df = analysis.run_query_df(reputation_laundering_query)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68738283",
   "metadata": {},
   "source": [
    "### High-velocity name changes\n",
    "\n",
    "There are many genuine reasons for a company to change its name, such as rebranding, mergers, or changes in business focus. However, a high frequency of name changes within a short period can be a red flag for potential fraud. This pattern may indicate an attempt to evade detection, create confusion among customers or investors, or distance the company from negative publicity. By analyzing the history of name changes for a company, we can identify those that exhibit this high-velocity pattern and may warrant further investigation.\n",
    "\n",
    "Because we organised the name history as a linked list, we can easily traverse it to count the number of name changes and identify companies that have changed their names multiple times within a short period. This can be done using a Cypher query that counts the number of `HAS_PREVIOUS_NAME` relationships for each company and filters for those with a high count within a specific timeframe.\n",
    "\n",
    "In the following graph visualization, we can see a company that has changed its name multiple times within a short period, which may be indicative of an attempt to evade detection or create confusion. Brown nodes represent the company, and red nodes represent its previous names. The thickness of the edges indicates the frequency of name changes, with thicker edges representing more frequent changes, and red edges representing more frequent changes. This visual representation can help us quickly identify companies that exhibit this high-velocity name change pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0ae1a6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_velocity_name_changes_query = \"\"\"\n",
    "// MATCH: Find the LONGEST path only\n",
    "// We anchor the start at a Company and the end at a PreviousName that has no further history.\n",
    "MATCH path = (c:Company)-[:HAS_PREVIOUS_NAME|PREVIOUS_NAME_OF*]->(last_n:PreviousName)\n",
    "WHERE NOT (last_n)-[:PREVIOUS_NAME_OF]->() \n",
    "\n",
    "// FILTER: Limit to chains with interesting history\n",
    "AND length(path) >= 5 \n",
    "\n",
    "// UNWIND: Now we can safely unwind because we only have one path per company\n",
    "WITH path, relationships(path) AS rels\n",
    "UNWIND range(0, size(rels)-1) AS i\n",
    "WITH rels[i] AS r_curr, \n",
    "     rels[i+1] AS r_next, \n",
    "     startNode(rels[i]) AS source, \n",
    "     endNode(rels[i]) AS target\n",
    "\n",
    "// CALCULATE: Duration\n",
    "// The logic: The name 'target' was valid FROM r_next.changed_on UNTIL r_curr.changed_on\n",
    "// If r_next is null (it's the oldest name), we assign a default large duration (e.g. 2000 days)\n",
    "WITH source, target, r_curr,\n",
    "     CASE \n",
    "       WHEN r_next IS NOT NULL THEN duration.between(r_next.changed_on, r_curr.changed_on).days \n",
    "       ELSE 2000 \n",
    "     END AS days_lasted\n",
    "\n",
    "// THICKNESS: Inverse of duration (Shorter time = Thicker line)\n",
    "// +1 ensures we don't divide by zero\n",
    "WITH source, target, r_curr, days_lasted,\n",
    "     toInteger(10.0 / (days_lasted + 5)) + 1 AS calculated_thickness\n",
    "\n",
    "// RETURN: Distinct virtual relationships\n",
    "RETURN \n",
    "    source, \n",
    "    target, \n",
    "    apoc.create.vRelationship(source, 'HAS_PREVIOUS_NAME', {\n",
    "        thickness: calculated_thickness,\n",
    "        days_held: days_lasted,\n",
    "        changed_on: r_curr.changed_on\n",
    "    }, target) AS rel\n",
    "LIMIT 50\n",
    "\"\"\"\n",
    "\n",
    "results = analysis.run_query_viz(high_velocity_name_changes_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "92416751",
   "metadata": {},
   "outputs": [],
   "source": [
    "VG = from_neo4j(results)\n",
    "\n",
    "VG.color_nodes(\n",
    "    field=\"caption\",  # Using the internal labels property\n",
    "    color_space=ColorSpace.DISCRETE,\n",
    "    colors=colors,\n",
    ")\n",
    "VG.resize_relationships(property=\"thickness\")\n",
    "# (Red = Fast, Blue = Slow)\n",
    "VG.color_relationships(\n",
    "    property=\"thickness\", color_space=ColorSpace.CONTINUOUS, colors=[\"blue\", \"red\"]\n",
    ")\n",
    "\n",
    "label_to_property = {\"PreviousName\": \"\", \"Company\": \"\"}\n",
    "\n",
    "analysis.set_caption_by_label(VG, label_to_property)\n",
    "\n",
    "generated_html = VG.render(layout=\"forcedirected\", initial_zoom=0.8)\n",
    "\n",
    "await analysis.capture_graph_to_png(\n",
    "    generated_html, \"renderings/high_velocity_name_changes_graph.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49fb5ae",
   "metadata": {},
   "source": [
    "![High-Velocity Name Changes](renderings/high_velocity_name_changes_graph.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "governance-kyc-psc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

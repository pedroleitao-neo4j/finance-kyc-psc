{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "957925a3",
   "metadata": {},
   "source": [
    "# Unraveling the UK Corporate Landscape: Geospatial Intelligence with Neo4j\n",
    "\n",
    "This notebook focuses on **Geospatial Intelligence**, leveraging the enriched address data within the Neo4j graph to visualize the physical footprint of the UK corporate landscape. By combining graph traversals with high-fidelity mapping libraries like [PyDeck](https://pydeck.gl/), we move beyond simple record retrieval to uncover spatial patterns, industry clusters, and geographic risk concentrations.\n",
    "\n",
    "The analysis answers critical questions about the physical distribution of economic activity. We visualize the density of registered businesses to identify commercial hubs, isolate \"graveyards\" of liquidated companies to detect potential fraud hotspots, and map the flow of control from UK assets to foreign jurisdictions. This spatial perspective is essential for understanding regional economic health, identifying shell company farms, and tracing cross-border beneficial ownership networks that may indicate capital flight or tax avoidance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5b77906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USER = os.getenv(\"NEO4J_USER\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "NEO4J_DATABASE = os.getenv(\"NEO4J_DATABASE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0b793c",
   "metadata": {},
   "source": [
    "## Analysis and Visualization Wrapper\n",
    "\n",
    "To streamline interactions with the database and rendering engines, we define a helper class, `Neo4jAnalysis`. This class abstracts the complexity of the Neo4j Python Driver, providing simplified methods for executing Cypher queries and returning results directly as Pandas DataFrames.\n",
    "\n",
    "Crucially, this class also includes a rendering utility, `capture_graph_to_png`. This method integrates with [Playwright](https://playwright.dev/python/) to launch a headless browser, render complex interactive PyDeck visualizations, and capture high-resolution screenshots. This capability allows us to automate the generation of static assets for reports while retaining the interactive capabilities of the underlying HTML visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b257b15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_analysis import Neo4jAnalysis\n",
    "\n",
    "# Initialize the analysis helper\n",
    "analysis = Neo4jAnalysis(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD, NEO4J_DATABASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0524cf",
   "metadata": {},
   "source": [
    "## Extracting Company Coordinates\n",
    "\n",
    "We execute a Cypher query to retrieve the geospatial coordinates of all companies in the graph. By matching `(:Company)` nodes with their connected `(:Address)` nodes, we filter for records where latitude and longitude properties are present. This dataset forms the baseline for our density analysis, representing the \"ground truth\" of where companies are physically registered across the UK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79f21c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_query = \"\"\"\n",
    "MATCH (c:Company)-[:REGISTERED_AT]->(a:Address)\n",
    "WHERE a.latitude IS NOT NULL AND a.longitude IS NOT NULL\n",
    "RETURN c.name AS name, a.latitude AS latitude, a.longitude AS longitude\n",
    "\"\"\"\n",
    "\n",
    "df = analysis.run_query_df(company_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67ea993",
   "metadata": {},
   "source": [
    "## Visualizing Company Density\n",
    "\n",
    "Using the extracted coordinate data, we generate a 3D Column Map to visualize company density. We group the data by unique coordinate pairs to calculate the volume of companies at each location. Using `pydeck`, we render these counts as extruded columns, where both the height and color of the column correspond to the number of companies. This visualization immediately highlights major economic centers, such as London, Manchester, and Birmingham, appearing as towering peaks in the topography of UK business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e42ba6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydeck as pdk\n",
    "import matplotlib\n",
    "import matplotlib.colors as mcolors\n",
    "import json\n",
    "\n",
    "grouped_df = (\n",
    "    df.groupby([\"latitude\", \"longitude\"]).size().reset_index(name=\"company_count\")\n",
    ")\n",
    "\n",
    "\n",
    "custom_colors = [\n",
    "    \"#4c8bf5\",\n",
    "    \"#9b59b6\",\n",
    "    \"#e74c3c\",\n",
    "]  # (Google Blue, Amethyst, Alizarin Red)\n",
    "cmap = mcolors.LinearSegmentedColormap.from_list(\"BluePurpleRed\", custom_colors)\n",
    "\n",
    "norm = mcolors.LogNorm(\n",
    "    vmin=grouped_df[\"company_count\"].min(), vmax=grouped_df[\"company_count\"].max()\n",
    ")\n",
    "\n",
    "\n",
    "def get_color(count):\n",
    "    rgba = cmap(norm(count))\n",
    "    return [\n",
    "        int(rgba[0] * 255),\n",
    "        int(rgba[1] * 255),\n",
    "        int(rgba[2] * 255),\n",
    "        220,\n",
    "    ]  # 220 = Transparency\n",
    "\n",
    "\n",
    "grouped_df[\"fill_color\"] = grouped_df[\"company_count\"].apply(get_color)\n",
    "\n",
    "# Sanitize Data\n",
    "geo_data_dict = json.loads(grouped_df.to_json(orient=\"records\"))\n",
    "\n",
    "# Define the Camera (UK Wide)\n",
    "view_state = pdk.ViewState(\n",
    "    latitude=54.5,\n",
    "    longitude=-3.0,\n",
    "    zoom=6.5,\n",
    "    pitch=45,\n",
    "    bearing=0,\n",
    ")\n",
    "\n",
    "layer = pdk.Layer(\n",
    "    \"ColumnLayer\",\n",
    "    data=geo_data_dict,\n",
    "    get_position=[\"longitude\", \"latitude\"],\n",
    "    # Height mapped to Count\n",
    "    get_elevation=\"company_count\",\n",
    "    elevation_scale=1,\n",
    "    radius=400,\n",
    "    get_fill_color=\"fill_color\",\n",
    "    pickable=True,\n",
    "    auto_highlight=True,\n",
    "    extruded=True,\n",
    "    material={\n",
    "        \"ambient\": 0.6,\n",
    "        \"diffuse\": 0.9,\n",
    "    },\n",
    ")\n",
    "\n",
    "r = pdk.Deck(\n",
    "    layers=[layer], initial_view_state=view_state, map_style=pdk.map_styles.CARTO_DARK\n",
    ")\n",
    "\n",
    "html_path = \"renderings/company_density_columns_3d.html\"\n",
    "r.to_html(html_path, notebook_display=False)\n",
    "\n",
    "await analysis.capture_graph_to_png(\n",
    "    html_content=None,\n",
    "    output_path=\"renderings/company_density_columns_3d.png\",\n",
    "    scale=1,\n",
    "    width=1500,\n",
    "    height=1920,\n",
    "    html_file=html_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc3b212",
   "metadata": {},
   "source": [
    "![Company Density Map](renderings/company_density_columns_3d.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fca578",
   "metadata": {},
   "source": [
    "\n",
    "## Extracting Liquidation Data\n",
    "\n",
    "Next we target a specific risk segment: companies that have entered liquidation. We modify our graph query to filter for companies linked to a `(:CompanyStatus)` node with the name 'Liquidation'. Extracting the coordinates for these specific entities allows us to move from general density to specific risk mapping, setting the stage for identifying geographic clusters of business failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b447b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_query = \"\"\"\n",
    "MATCH (c:Company)-[:REGISTERED_AT]->(a:Address)\n",
    "WHERE a.latitude IS NOT NULL AND a.longitude IS NOT NULL\n",
    "MATCH (c)-[:HAS_STATUS]->(s:CompanyStatus)\n",
    "WHERE s.name = 'Liquidation'\n",
    "RETURN c.name AS name, a.latitude AS latitude, a.longitude AS longitude\n",
    "\"\"\"\n",
    "\n",
    "df = analysis.run_query_df(company_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4616bea",
   "metadata": {},
   "source": [
    "## Heatmap of Liquidation Clusters\n",
    "\n",
    "We visualize the liquidation data using a Gaussian Heatmap. Unlike the column map which shows exact counts, the heatmap aggregates the intensity of points to create a continuous surface of \"risk.\" We define a custom color gradient, ranging from cool blues to intense reds, to represent the density of failed companies. This visualization helps analysts spot potential \"phoenixing\" hubs or areas with abnormally high insolvency rates that may warrant further investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bbd166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "grouped_df = (\n",
    "    df.groupby([\"latitude\", \"longitude\"]).size().reset_index(name=\"company_count\")\n",
    ")\n",
    "\n",
    "geo_data_dict = json.loads(grouped_df.to_json(orient=\"records\"))\n",
    "\n",
    "# 1. Define the Camera (UK Wide)\n",
    "view_state = pdk.ViewState(\n",
    "    latitude=54.5,\n",
    "    longitude=-3.0,\n",
    "    zoom=6.5,\n",
    "    pitch=45,  # Top-down view is best for 2D heatmaps\n",
    "    bearing=0,\n",
    ")\n",
    "\n",
    "# 2. Define the Heatmap Layer\n",
    "layer = pdk.Layer(\n",
    "    \"HeatmapLayer\",\n",
    "    data=geo_data_dict,\n",
    "    get_position=[\"longitude\", \"latitude\"],\n",
    "    get_weight=\"company_count\",\n",
    "    radiusPixels=30,  # Radius of the \"glow\" around each point (in pixels, not meters)\n",
    "    intensity=1.0,  # Multiplier for the heat value\n",
    "    threshold=0.05,  # Cutoff: Hide areas with very low density (reduces visual noise)\n",
    "    pickable=True,\n",
    "    color_range=[\n",
    "        [65, 182, 196],  # Light Blue (Low Density)\n",
    "        [44, 127, 184],  # Medium Blue\n",
    "        [37, 52, 148],  # Deep Blue\n",
    "        [128, 0, 128],  # Purple\n",
    "        [220, 20, 60],  # Crimson\n",
    "        [255, 0, 0],  # Bright Red (High Density)\n",
    "    ],\n",
    ")\n",
    "\n",
    "# 3. Render\n",
    "r = pdk.Deck(\n",
    "    layers=[layer],\n",
    "    initial_view_state=view_state,\n",
    "    map_style=pdk.map_styles.CARTO_DARK,  # Dark maps make heatmaps glow properly\n",
    ")\n",
    "\n",
    "html_path = \"renderings/liquidation_density_heatmap_3d.html\"\n",
    "r.to_html(html_path, notebook_display=False)\n",
    "\n",
    "await analysis.capture_graph_to_png(\n",
    "    html_content=None,\n",
    "    output_path=\"renderings/liquidation_density_heatmap_3d.png\",\n",
    "    scale=1,\n",
    "    width=1500,\n",
    "    height=1920,\n",
    "    html_file=html_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cd327f",
   "metadata": {},
   "source": [
    "![Liquidation Density Heatmap](renderings/liquidation_density_heatmap_3d.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6133208",
   "metadata": {},
   "source": [
    "## Industry Sector Dominance\n",
    "\n",
    "This complex query analyzes the industrial character of different locations. For every coordinate cluster, it retrieves the Standard Industrial Classification (SIC) codes of the registered companies. It then aggregates this data to determine the *dominant* industry at that specific location, essentially asking, \"What is the primary business of this street or building?\" The query extracts the sector division (the first two digits of the SIC code) to categorize the location into broad industries like Technology, Manufacturing, or Finance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96b55896",
   "metadata": {},
   "outputs": [],
   "source": [
    "sic_codes_query = \"\"\"\n",
    "MATCH (c:Company)-[:REGISTERED_AT]->(a:Address)\n",
    "WHERE a.latitude IS NOT NULL AND a.longitude IS NOT NULL\n",
    "\n",
    "// 1. Get the single effective SIC code for the company (same as before)\n",
    "MATCH (c)-[:HAS_SIC]->(s:SICCode)\n",
    "WITH c, a, s\n",
    "ORDER BY s.code\n",
    "WITH c, a, head(collect(s.code)) as company_sic\n",
    "\n",
    "// 2. Count the frequency of each SIC code at each specific coordinate\n",
    "//    We group by Lat, Lon, and SIC here.\n",
    "WITH a.latitude as lat, a.longitude as lon, company_sic, count(*) as frequency\n",
    "ORDER BY frequency DESC\n",
    "\n",
    "// 3. Group by Coordinate only, collecting the (SIC, frequency) pairs.\n",
    "//    Since we ordered by frequency DESC above, the first item in the list is the dominant one.\n",
    "WITH lat, lon, collect({code: company_sic, count: frequency}) as sic_stats\n",
    "WITH lat, lon, sic_stats[0] as dominant_stat\n",
    "\n",
    "RETURN \n",
    "    lat as latitude, \n",
    "    lon as longitude, \n",
    "    dominant_stat.code as sic_code,\n",
    "    // Extract the 'Division' from the dominant SIC\n",
    "    substring(dominant_stat.code, 0, 2) as sector_id,\n",
    "    // Optional: Return the count so you can visualize 'strength' (e.g., opacity)\n",
    "    dominant_stat.count as dominance_strength\n",
    "LIMIT 20000\n",
    "\"\"\"\n",
    "\n",
    "df = analysis.run_query_df(sic_codes_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7113abdd",
   "metadata": {},
   "source": [
    "## Visualizing Industrial Hubs\n",
    "\n",
    "We map the dominant industries using a Scatterplot Layer. We define a custom color palette that assigns distinct hues to specific economic sectors, for example, mapping \"Information & Communication\" to Cyan and \"Finance\" to Emerald Green. The radius of each point is scaled by the \"dominance strength\" (the number of companies in that cluster). This creates a vivid map of economic specialization, clearly distinguishing the Tech City in Shoreditch from the financial strongholds of Canary Wharf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c4c5b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: '62' = Computer programming, '70' = Head office, etc.\n",
    "def get_sector_color(sector_id):\n",
    "    s = str(sector_id).strip()\n",
    "\n",
    "    # Agriculture, Forestry, Fishing (01-03) -> Green/Brown\n",
    "    if s in [\"01\", \"02\", \"03\"]:\n",
    "        return [34, 139, 34]\n",
    "    # Mining & Quarrying (05-09) -> Dark Grey\n",
    "    if s in [\"05\", \"06\", \"07\", \"08\", \"09\"]:\n",
    "        return [105, 105, 105]\n",
    "\n",
    "    # Manufacturing (10-33) -> Purple/Slate\n",
    "    if \"10\" <= s <= \"33\":\n",
    "        return [147, 112, 219]\n",
    "    # Energy, Water, Waste (35-39) -> Electric Blue\n",
    "    if s in [\"35\", \"36\", \"37\", \"38\", \"39\"]:\n",
    "        return [0, 191, 255]\n",
    "    # Construction (41-43) -> Yellow/Orange (High Vis)\n",
    "    if s in [\"41\", \"42\", \"43\"]:\n",
    "        return [255, 215, 0]\n",
    "\n",
    "    # Wholesale & Retail Trade (45-47) -> Red\n",
    "    if s in [\"45\", \"46\", \"47\"]:\n",
    "        return [220, 20, 60]\n",
    "    # Transport & Storage (49-53) -> Navy Blue\n",
    "    if s in [\"49\", \"50\", \"51\", \"52\", \"53\"]:\n",
    "        return [0, 0, 128]\n",
    "    # Accommodation & Food Service (55-56) -> Pink/Coral\n",
    "    if s in [\"55\", \"56\"]:\n",
    "        return [255, 127, 80]\n",
    "\n",
    "    # Information & Communication (58-63) -> Cyan/Teal\n",
    "    # Note: 62 (Programming) is dominant, so we keep it distinct if needed\n",
    "    if s in [\"58\", \"59\", \"60\", \"61\", \"62\", \"63\"]:\n",
    "        return [0, 255, 255]\n",
    "\n",
    "    # Financial & Insurance (64-66) -> Emerald Green\n",
    "    if s in [\"64\", \"65\", \"66\"]:\n",
    "        return [46, 139, 87]\n",
    "    # Real Estate (68) -> Magenta\n",
    "    if s == \"68\":\n",
    "        return [255, 0, 255]\n",
    "\n",
    "    # Professional, Scientific & Technical (69-75) -> Orange\n",
    "    if s in [\"69\", \"70\", \"71\", \"72\", \"73\", \"74\", \"75\"]:\n",
    "        return [255, 165, 0]\n",
    "    # Administrative & Support Service (77-82) -> Light Grey/Blue\n",
    "    if s in [\"77\", \"78\", \"79\", \"80\", \"81\", \"82\"]:\n",
    "        return [176, 196, 222]\n",
    "\n",
    "    # Education (85) -> Blue (Academic)\n",
    "    if s == \"85\":\n",
    "        return [65, 105, 225]\n",
    "    # Health & Social Work (86-88) -> Red Cross Red (or softer Pink)\n",
    "    if s in [\"86\", \"87\", \"88\"]:\n",
    "        return [255, 105, 180]\n",
    "    # Arts, Entertainment & Recreation (90-93) -> Violet\n",
    "    if s in [\"90\", \"91\", \"92\", \"93\"]:\n",
    "        return [138, 43, 226]\n",
    "\n",
    "    # Default (Unknown/Other) -> Dark Grey\n",
    "    return [80, 80, 80]\n",
    "\n",
    "\n",
    "df[\"color\"] = df[\"sector_id\"].apply(lambda x: get_sector_color(str(x)) + [200])\n",
    "\n",
    "# Scale the radius so big clusters are visible but don't cover the map\n",
    "#    We use a simple square root scale so 100x companies = 10x width\n",
    "df[\"radius\"] = df[\"dominance_strength\"].apply(lambda x: (x**0.5) * 20)\n",
    "\n",
    "view_state = pdk.ViewState(\n",
    "    latitude=54.5,\n",
    "    longitude=-3.0,\n",
    "    zoom=6.5,\n",
    "    pitch=45,\n",
    "    bearing=0,\n",
    ")\n",
    "\n",
    "geo_data_dict = json.loads(df.to_json(orient=\"records\"))\n",
    "\n",
    "layer = pdk.Layer(\n",
    "    \"ScatterplotLayer\",\n",
    "    data=geo_data_dict,\n",
    "    get_position=[\"longitude\", \"latitude\"],\n",
    "    get_fill_color=\"color\",\n",
    "    get_radius=\"radius\",\n",
    "    pickable=True,\n",
    "    opacity=0.8,\n",
    "    stroked=True,\n",
    "    filled=True,\n",
    "    radius_min_pixels=3,\n",
    "    radius_max_pixels=50,\n",
    ")\n",
    "\n",
    "r = pdk.Deck(\n",
    "    layers=[layer],\n",
    "    initial_view_state=view_state,\n",
    "    map_style=pdk.map_styles.CARTO_DARK,\n",
    "    tooltip={\n",
    "        \"html\": \"<b>Sector:</b> {sector_id}<br/>\"\n",
    "        \"<b>Dominant Type:</b> {sic_code}<br/>\"\n",
    "        \"<b>Cluster Size:</b> {dominance_strength} companies\"\n",
    "    },\n",
    ")\n",
    "\n",
    "html_path = \"renderings/sic_code_distribution.html\"\n",
    "r.to_html(html_path, notebook_display=False)\n",
    "\n",
    "await analysis.capture_graph_to_png(\n",
    "    html_content=None,\n",
    "    output_path=\"renderings/sic_code_distribution.png\",\n",
    "    scale=1,\n",
    "    width=1500,\n",
    "    height=1920,\n",
    "    html_file=html_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996c6cbe",
   "metadata": {},
   "source": [
    "![SIC Code Distribution](renderings/sic_code_distribution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4101f9e6",
   "metadata": {},
   "source": [
    "## Financial District Analysis\n",
    "\n",
    "We narrow our focus to the Financial sector within the Greater London area. The query filters for companies with SIC codes containing \"finance\" or \"financial\" and utilizes Neo4j's spatial functions (`point.distance`) to retain only those within a 50km radius of central London. We then aggregate these counts by postcode district (e.g., \"EC2M\"), preparing the data for a choropleth map that compares the density of financial institutions across different administrative boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba35e498",
   "metadata": {},
   "outputs": [],
   "source": [
    "finance_district_query = \"\"\"\n",
    "MATCH (c:Company)-[:HAS_SIC]-(sc:SICCode)\n",
    "WHERE toLower(sc.code) CONTAINS 'finance' OR toLower(sc.code) CONTAINS 'financial'\n",
    "MATCH (c)-[:REGISTERED_AT]->(a:Address)\n",
    "WHERE a.latitude IS NOT NULL AND a.longitude IS NOT NULL\n",
    "  AND point.distance(\n",
    "      point({latitude: a.latitude, longitude: a.longitude}),\n",
    "      point({latitude: 51.5074, longitude: -0.1278})\n",
    "  ) < 50000  // 50km Radius\n",
    "// Extract the District (e.g., 'EC2M' from 'EC2M 7PP')\n",
    "WITH split(a.postcode, ' ')[0] AS district, count(c) AS company_count\n",
    "RETURN district, company_count\n",
    "ORDER BY company_count DESC\n",
    "\"\"\"\n",
    "\n",
    "df = analysis.run_query_df(finance_district_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e94e38",
   "metadata": {},
   "source": [
    "## Geospatial Boundary Integration\n",
    "\n",
    "To render a choropleth map, we require the actual geometric shapes of the postcode districts. This cell dynamically fetches GeoJSON boundary files from an external repository for the districts identified in our query. It merges these geometric shapes with our financial company counts into a unified GeoDataFrame. We also compute the color values for each district in Python, applying a logarithmic scale to ensure that the intense density of the City of London doesn't visually drown out smaller financial hubs in the periphery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b091e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import re\n",
    "\n",
    "\n",
    "def get_postcode_area(district):\n",
    "    # Extracts the leading letters (e.g., \"SW\" from \"SW1A\", \"B\" from \"B1\")\n",
    "    match = re.match(r\"([A-Z]+)\", district, re.I)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "\n",
    "df[\"area\"] = df[\"district\"].apply(get_postcode_area)\n",
    "\n",
    "unique_areas = df[\"area\"].dropna().unique()\n",
    "base_url = \"https://raw.githubusercontent.com/missinglink/uk-postcode-polygons/refs/heads/master/geojson\"\n",
    "\n",
    "gdf_list = []\n",
    "\n",
    "for area in unique_areas:\n",
    "    url = f\"{base_url}/{area.upper()}.geojson\"\n",
    "    try:\n",
    "        # Fetch the file from GitHub\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            # Read GeoJSON from memory\n",
    "            area_gdf = gpd.read_file(io.BytesIO(response.content))\n",
    "            gdf_list.append(area_gdf)\n",
    "        else:\n",
    "            print(f\"Warning: Could not find {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {area}: {e}\")\n",
    "\n",
    "if not gdf_list:\n",
    "    raise ValueError(\"No GeoJSON data could be retrieved.\")\n",
    "\n",
    "# Combine all downloaded areas into one main GeoDataFrame\n",
    "full_gdf = pd.concat(gdf_list, ignore_index=True)\n",
    "if full_gdf.crs and full_gdf.crs.to_string() != \"EPSG:4326\":\n",
    "    full_gdf = full_gdf.to_crs(epsg=4326)\n",
    "\n",
    "# The GeoJSONs usually have a 'name' property matching the district (e.g., \"AB10\")\n",
    "merged_gdf = full_gdf.merge(df, left_on=\"name\", right_on=\"district\", how=\"left\")\n",
    "merged_gdf[\"company_count\"] = merged_gdf[\"company_count\"].fillna(0)\n",
    "\n",
    "# We calculate colors in Python to keep PyDeck fast\n",
    "cmap = matplotlib.colormaps[\"YlOrRd\"]\n",
    "norm = mcolors.LogNorm(vmin=1, vmax=merged_gdf[\"company_count\"].max())\n",
    "\n",
    "\n",
    "def get_fill_color(count):\n",
    "    if count == 0:\n",
    "        return [30, 30, 155, 150]  # Transparent blueish grey for empty districts\n",
    "    rgba = cmap(norm(count))\n",
    "    return [int(rgba[0] * 255), int(rgba[1] * 255), int(rgba[2] * 255), 200]\n",
    "\n",
    "\n",
    "merged_gdf[\"fill_color\"] = merged_gdf[\"company_count\"].apply(get_fill_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f5176d",
   "metadata": {},
   "source": [
    "## Finance Sector Choropleth\n",
    "\n",
    "We render the financial density data using a `GeoJsonLayer`. This visualization paints each postcode district according to its calculated heat value and extrudes the shape based on the company count. The result is a 3D landscape of the financial sector, providing a clear, district-level view of how the industry radiates outward from the City of London and Canary Wharf into the surrounding boroughs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cfd8b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_data_dict = json.loads(merged_gdf.to_json())\n",
    "\n",
    "view_state = pdk.ViewState(\n",
    "    latitude=51.5074,  # Centered on London\n",
    "    longitude=-0.1278,\n",
    "    zoom=8.5,  # Zoomed out to see Oxford, Cambridge, and Brighton\n",
    "    pitch=45,  # Tilted to show the 3D height of the bars\n",
    "    bearing=-35,  # North is roughly up\n",
    ")\n",
    "\n",
    "layer = pdk.Layer(\n",
    "    \"GeoJsonLayer\",\n",
    "    data=geo_data_dict,\n",
    "    opacity=0.8,\n",
    "    stroked=True,\n",
    "    filled=True,\n",
    "    extruded=True,\n",
    "    wireframe=False,\n",
    "    get_fill_color=\"properties.fill_color\",\n",
    "    get_line_color=[255, 255, 255, 50],\n",
    "    get_elevation=\"properties.company_count * 3\",  # Scale elevation for better visibility\n",
    "    get_line_width=50,\n",
    "    pickable=True,\n",
    "    auto_highlight=True,\n",
    ")\n",
    "\n",
    "r = pdk.Deck(\n",
    "    layers=[layer],\n",
    "    initial_view_state=view_state,\n",
    "    map_style=pdk.map_styles.CARTO_DARK,\n",
    "    tooltip={\"html\": \"<b>{name}</b><br/>Finance Companies: {company_count}\"},\n",
    ")\n",
    "\n",
    "html_path = \"renderings/finance_choropleth_dynamic.html\"\n",
    "r.to_html(html_path, notebook_display=False)\n",
    "\n",
    "await analysis.capture_graph_to_png(\n",
    "    html_content=None,\n",
    "    output_path=\"renderings/finance_choropleth_dynamic.png\",\n",
    "    scale=1,\n",
    "    width=1500,\n",
    "    height=1920,\n",
    "    html_file=html_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fceb6a0",
   "metadata": {},
   "source": [
    "![Financial Industry Choropleth](renderings/finance_choropleth_dynamic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91a3544",
   "metadata": {},
   "source": [
    "## Cross-Border Outflow Extraction\n",
    "\n",
    "This cell initiates the analysis of international control networks. We execute two parallel queries to sample \"outflows\": UK companies controlled by Persons residing abroad, and UK companies controlled by Organizations based abroad. By filtering out the UK as the country of residence, we isolate the connections that bridge international borders. We retrieve the coordinates of the UK registered office (Source) and the foreign country (Target) to map the vectors of external influence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a845b0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "outflows_persons_query = \"\"\"\n",
    "MATCH (p:Person)-[:LIVES_AT]->(pa:Address)\n",
    "MATCH (p)-[:RESIDES_IN]->(co:Country)\n",
    "MATCH (p)-[:CONTROLS]->(c:Company)-[:REGISTERED_AT]->(ca:Address)\n",
    "WHERE co.name <> 'United Kingdom'\n",
    "  AND pa.latitude IS NOT NULL AND pa.longitude IS NOT NULL\n",
    "  AND ca.latitude IS NOT NULL AND ca.longitude IS NOT NULL\n",
    "WITH p, pa, c, ca, co\n",
    "ORDER BY rand()\n",
    "LIMIT 2000\n",
    "RETURN\n",
    "    p.name as controller,\n",
    "    c.name as company,\n",
    "    ca.latitude as src_lat, \n",
    "    ca.longitude as src_lon,\n",
    "    co.name as country,\n",
    "    'Person' as type\n",
    "\"\"\"\n",
    "\n",
    "outflows_org_query = \"\"\"\n",
    "MATCH (o:Organization)-[:REGISTERED_AT]->(pa:Address)\n",
    "MATCH (o)-[:BASED_IN]->(co:Country)\n",
    "MATCH (o)-[:CONTROLS]->(c:Company)-[:REGISTERED_AT]->(ca:Address)\n",
    "WHERE co.name <> 'United Kingdom'\n",
    "  AND pa.latitude IS NOT NULL AND pa.longitude IS NOT NULL\n",
    "  AND ca.latitude IS NOT NULL AND ca.longitude IS NOT NULL\n",
    "WITH o, pa, c, ca, co\n",
    "ORDER BY rand()\n",
    "LIMIT 2000\n",
    "RETURN\n",
    "    o.name as controller,\n",
    "    c.name as company,\n",
    "    ca.latitude as src_lat, \n",
    "    ca.longitude as src_lon,\n",
    "    co.name as country,\n",
    "    'Organization' as type\n",
    "\"\"\"\n",
    "\n",
    "df_persons = analysis.run_query_df(outflows_persons_query)\n",
    "\n",
    "df_orgs = analysis.run_query_df(outflows_org_query)\n",
    "\n",
    "df = pd.concat([df_persons, df_orgs], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9e5128",
   "metadata": {},
   "source": [
    "## Mapping Global Control Networks\n",
    "\n",
    "We visualize the international ownership connections using an Arc Layer. We define a dictionary of centroids for key countries to serve as the destination points for our arcs. The visualization draws lines from the UK to the controller's country of residence, with the color of the arc transitioning from white (source) to a color representing the volume of connections (target). This \"spider web\" map effectively highlights the jurisdictions that exert the most significant control over UK assets (arcs ending in **red** as to opposed to **blue**, which exert the least influence), making it easy to spot heavy inflows from tax havens or specific foreign powers.\n",
    "\n",
    "> Note the heavy concentration of arcs pointing towards the Jersey Channel Islands, a notorious tax haven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "847438fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNTRY_CENTROIDS = {\n",
    "    # Europe\n",
    "    \"Austria\": [14.5501, 47.5162],\n",
    "    \"Belgium\": [4.4699, 50.5039],\n",
    "    \"Bulgaria\": [25.4858, 42.7339],\n",
    "    \"Croatia\": [15.2000, 45.1000],\n",
    "    \"Cyprus\": [33.4299, 35.1264],\n",
    "    \"Czech Republic\": [15.4730, 49.8175],\n",
    "    \"Denmark\": [9.5018, 56.2639],\n",
    "    \"Estonia\": [25.0136, 58.5953],\n",
    "    \"Finland\": [25.7482, 61.9241],\n",
    "    \"France\": [2.2137, 46.2276],\n",
    "    \"Germany\": [10.4515, 51.1657],\n",
    "    \"Greece\": [21.8243, 39.0742],\n",
    "    \"Hungary\": [19.5033, 47.1625],\n",
    "    \"Ireland\": [-8.2439, 53.4129],\n",
    "    \"Italy\": [12.5674, 41.8719],\n",
    "    \"Latvia\": [24.6032, 56.8796],\n",
    "    \"Lithuania\": [23.8813, 55.1694],\n",
    "    \"Luxembourg\": [6.1296, 49.8153],\n",
    "    \"Malta\": [14.3754, 35.9375],\n",
    "    \"Netherlands\": [5.2913, 52.1326],\n",
    "    \"Poland\": [19.1451, 51.9194],\n",
    "    \"Portugal\": [-8.2245, 39.3999],\n",
    "    \"Romania\": [24.9668, 45.9432],\n",
    "    \"Slovakia\": [19.6990, 48.6690],\n",
    "    \"Slovenia\": [14.9955, 46.1512],\n",
    "    \"Spain\": [-3.7492, 40.4637],\n",
    "    \"Sweden\": [18.6435, 60.1282],\n",
    "    \"Switzerland\": [8.2275, 46.8182],\n",
    "    # Tax Havens / Crown Dependencies\n",
    "    \"Jersey\": [-2.1312, 49.2144],\n",
    "    \"Guernsey\": [-2.5853, 49.4482],\n",
    "    \"Isle of Man\": [-4.5481, 54.2361],\n",
    "    \"British Virgin Islands\": [-64.6399, 18.4207],\n",
    "    \"Cayman Islands\": [-81.2546, 19.3133],\n",
    "    \"Bermuda\": [-64.7574, 32.3078],\n",
    "    \"Bahamas\": [-77.3963, 25.0343],\n",
    "    \"Panama\": [-80.7821, 8.5380],\n",
    "    \"Seychelles\": [55.4920, -4.6796],\n",
    "    # Asia & Middle East\n",
    "    \"China\": [104.1954, 35.8617],\n",
    "    \"Hong Kong\": [114.1694, 22.3193],\n",
    "    \"Japan\": [138.2529, 36.2048],\n",
    "    \"Singapore\": [103.8198, 1.3521],\n",
    "    \"Australia\": [133.7751, -25.2744],\n",
    "    \"India\": [78.9629, 20.5937],\n",
    "    \"Russia\": [105.3188, 61.5240],\n",
    "    \"Turkey\": [35.2433, 38.9637],\n",
    "    \"United Arab Emirates\": [53.8478, 23.4241],\n",
    "    # Northern Africa\n",
    "    \"Morocco\": [-7.0926, 31.7917],\n",
    "    \"Algeria\": [1.6596, 28.0339],\n",
    "    \"Tunisia\": [9.5375, 33.8869],\n",
    "}\n",
    "\n",
    "\n",
    "def get_centroid(country_name):\n",
    "    return COUNTRY_CENTROIDS.get(str(country_name).strip(), [None, None])\n",
    "\n",
    "\n",
    "# Apply Centroids\n",
    "coords = df[\"country\"].apply(get_centroid)\n",
    "df[\"tgt_lon\"] = coords.apply(lambda x: x[0])\n",
    "df[\"tgt_lat\"] = coords.apply(lambda x: x[1])\n",
    "\n",
    "df_clean = df.dropna(subset=[\"tgt_lat\", \"tgt_lon\"]).copy()\n",
    "\n",
    "country_counts = df_clean[\"country\"].value_counts()\n",
    "count_map = country_counts.to_dict()\n",
    "min_val = country_counts.min()\n",
    "max_val = country_counts.max()\n",
    "\n",
    "\n",
    "# Define a function to generate a Blue -> Red gradient based on count\n",
    "def get_heat_color(country):\n",
    "    count = count_map.get(country, 0)\n",
    "\n",
    "    # Normalize the count to a 0.0 - 1.0 scale\n",
    "    # Prevent division by zero if only one country exists or min == max\n",
    "    if max_val == min_val:\n",
    "        ratio = 0.5\n",
    "    else:\n",
    "        ratio = (count - min_val) / (max_val - min_val)\n",
    "\n",
    "    # Linear Interpolation:\n",
    "    # Low (0.0) = Blue [0, 0, 255]\n",
    "    # High (1.0) = Red [255, 0, 0]\n",
    "\n",
    "    r = int(255 * ratio)\n",
    "    g = 0  # Keeping green at 0 for a sharp Blue-Purple-Red transition\n",
    "    b = int(255 * (1 - ratio))\n",
    "\n",
    "    return [r, g, b, 160]  # Add Alpha channel (transparency)\n",
    "\n",
    "\n",
    "# Apply the color and store the count for the tooltip\n",
    "df_clean[\"color\"] = df_clean[\"country\"].apply(get_heat_color)\n",
    "df_clean[\"count\"] = df_clean[\"country\"].map(count_map)\n",
    "\n",
    "geo_data_dict = df_clean.to_dict(orient=\"records\")\n",
    "\n",
    "view_state = pdk.ViewState(\n",
    "    latitude=50.5, longitude=12.5, zoom=4.4, pitch=55, bearing=30\n",
    ")\n",
    "\n",
    "layer = pdk.Layer(\n",
    "    \"ArcLayer\",\n",
    "    data=geo_data_dict,\n",
    "    # SOURCE: UK Company\n",
    "    get_source_position=[\"src_lon\", \"src_lat\"],\n",
    "    # TARGET: Foreign Controller\n",
    "    get_target_position=[\"tgt_lon\", \"tgt_lat\"],\n",
    "    get_source_color=[255, 255, 255, 60],  # Faint white source\n",
    "    get_target_color=\"color\",  # Colored target\n",
    "    get_width=2,\n",
    "    get_tilt=15,\n",
    "    pickable=True,\n",
    ")\n",
    "\n",
    "r = pdk.Deck(\n",
    "    layers=[layer],\n",
    "    initial_view_state=view_state,\n",
    "    map_style=pdk.map_styles.CARTO_DARK,\n",
    "    tooltip={\n",
    "        \"html\": \"<b>Controller:</b> {controller} ({type})<br/><b>Location:</b> {country}<br/><b>Company:</b> {company}\"\n",
    "    },\n",
    ")\n",
    "\n",
    "html_path = \"renderings/unified_outflows.html\"\n",
    "r.to_html(html_path, notebook_display=False)\n",
    "\n",
    "await analysis.capture_graph_to_png(\n",
    "    html_content=None,\n",
    "    output_path=\"renderings/unified_outflows.png\",\n",
    "    scale=1,\n",
    "    width=1500,\n",
    "    height=1920,\n",
    "    html_file=html_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf5c253",
   "metadata": {},
   "source": [
    "![Outflows](renderings/unified_outflows.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "governance-kyc-psc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
